<!DOCTYPE html>
<html>
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width,initial-scale=1">
        <meta property="og:type" content="website">

        <!-- !!! Change the background image of the page to your header image by changing the ".background-image" property in main.css. -->
        <!-- !!! I added a fancy gradient effect to have the page's color gradually go from the color at the bottom of the image to black. 
        I did that like this: background-image: url('./img/task2-side.png'), linear-gradient(to bottom, rgb(122, 115, 110), #222222); -->

        <title>Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction</title>
        <!-- -------------- -->
        <!-- OPENGRAPH INFO: This is what will populate the "cards" that show up when you post the link on Facebook, Slack, etc. -->
        <!-- -------------- -->
        
        <meta name="description" content="Research from Waterloo HCI: Near-Keyboard Hand Postures for Expanded Laptop Interaction">
        <meta name="keywords" content="!!! KEYWORDS HERE">
        <meta name="author" content="Nalin Chhibber, Hemant Surale, Fabrice Matulic, Daniel Vogel from University of Waterloo">
        <meta property="og:title" content="Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction">
        <meta property="og:description" content="Research from Waterloo HCI: Near-Keyboard Hand Postures for Expanded Laptop Interaction">

        <!-- The URL for your site. For social media posts etc. -->
        <meta property="og:url" content="https://typealike.github.io/">

        <!-- Header image. Important to put a good, representative image here as this is what shows on clickable links! -->
        <meta property="og:image" content="img/Figure2.png">

        <!-- Info specifically for Twitter posts. Keep it the same as the other stuff. -->
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:site" content="@nalinchhibber">
        <meta name="twitter:creator" content="@nalinchhibber">
        <meta name="twitter:title" content="Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction">
        <meta name="twitter:description" content="Research from Waterloo HCI: Near-Keyboard Hand Postures for Expanded Laptop Interaction">
        <meta name="twitter:image" content="img/Figure2.png">
        
        <!-- <link rel="apple-touch-icon" href="apple-touch-icon.png"> --><!-- Place favicon.ico in the root directory -->
        <link rel="stylesheet" href="./main.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700&display=swap" rel="stylesheet">        
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/css/bootstrap.min.css" integrity="sha384-Smlep5jCw/wG7hdkwQ/Z5nLIefveQRIY9nfy6xoR1uRYBtpZgI6339F5dgvm/e9B" crossorigin="anonymous">
    
        <!-- This is where you'd paste your Google Analytics tag if you feel like having it. -->

        <!-- <script async src="https://www.googletagmanager.com/gtag/... -->

    </head>
    <body>
        <div id="header" class="col-md-10 col-sm-12 offset-md-1 offset-sm-0">
            <p class="title">Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction</p>
            <p class="authors">Nalin Chhibber, Hemant Surale, Fabrice Matulic, Daniel Vogel</p>
            <img class="pad-right" src="img/wathci.png">
		https://github.com/typealike
	    <a class="download-link rounded col-xs-12" href="https://github.com/typealike">Code</a>
            <a class="download-link rounded col-xs-12" href="assets/Typealike.pdf">Paper</a>
        </div>
        <div id="content" class="col-md-10 col-xs-12 offset-md-1">
            <div id="teaser" class="col-10 offset-1 content-section">
                <blockquote>Typealike postures are postures formed using the left or right hand, an open or closed hand form, and different wrist orientations, all further distinguished by hand position when on, just beside, or just below the keyboard.</blockquote>
                <!-- !!! TEASER IMAGE HERE  -->
                <img class="figure col-lg-10 img-fluid mx-auto d-block" src="img/teaser.png">
		<p>Different postures can trigger different interactions, for example: 
			(a) an open left hand at 90&#176; wrist rotation beside the keyboard can decrease the volume; 
			(b) an open left hand at 0&#176; on the keyboard can open a screen capture snipping tool; 
			(c) a closed right hand 0&#176; posture below the keyboard could turn the car in a racing game; 
			(d) an open right hand at 0&#176; on the keyboard could advance a document page; and 
			(e) a right open 90&#176; hand posture beside the keyboard could increase the volume.
		    </p>
            </div>

            <div id="findings" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>Quick Facts</h1>
                <div class="row">
                    <div class="col-xl-6 offset-xl-0col-xs-12">
			<p>Overall, our work contributes:</p>
                        <ol class="findings-row">
                            <li class="findings-text">    
			    A set of near-keyboard hand postures that are acceptable to users, recognized reliably, and fast to perform.
			    </li>
  			    <li class="findings-text">
			    A dataset of nearly 350K posture images captured under different lighting conditions and two keyboard backgrounds
			    </li>
                        </ol>
		        <p>
			We evaluate our approach by answering three questions: Is this style of postures preferable by users? Can they be recognized reliably? Are they quick and easy to perform? 
			</p>
                    </div>
                    <div class="col-xl-6 offset-xl-0col-xs-12">
                        <div class="embed-responsive embed-responsive-16by9">
                            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/9MA2HexW_cg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>  
            </div>

            <div id="guide" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>Design Considerations for the Interaction Vocubulary</h1>
		<p>
		    Our posture set was chosen to support our goal of a discrete command invoking method that aligns with natural laptop
		usage. The postures are variations of hand posture styles, all based on three design considerations:
			</p>
                <ul>
                <li>
			<b>Recognition without a key press:</b> 
			<p>Postures should not conflict with touch-typing hand motor behaviour when pressing keys and “disentangle” command execution from key-press events</p>
		</li>
                <li><b>Performed on or near the keyboard surface: </b>
			<p>Postures should be compatible with maintaining a near-resting arm posture where the wrist is in constant contact with the laptop case.</p>
			</li>
		<li><b>Simple and easy to perform:</b>
			<p>
			Postures should be naturally comfortable to perform for the user but still distinguishable for detection in order to be practical.
			</p>
			</li>
       </ul>
            </div>

            <div id="abstract" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>Abstract</h1>
                <p>
                    We propose a style of hand postures to trigger commands on a laptop. The key idea is to perform hand-postures while keeping the hands on, beside, or below the keyboard, to align with natural laptop usage. 36 hand-posture variations are explored considering three resting locations, left or right hand, open or closed hand, and three wrist rotation angles. A 30-participant formative study measures posture preferences and generates a dataset of nearly 350K images under different lighting conditions and backgrounds. A deep learning recognizer achieves over 97% accuracy when classifying all 36 postures with 2 additional non-posture classes for typing and non-typing. A second experiment with 20 participants validates the recognizer under real-time usage and compares posture invocation time with keyboard shortcuts. Results find low error rates and fast formation time, indicating postures are close to current typing and pointing postures. Finally, practical use case demonstrations are presented, and further extensions discussed.
                </p>
            </div>

            <div id="technique" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>Technique</h1>
		    
		<p>
		With these design considerations in mind, we created a style of postures that use different hand forms, kinematics of wrist rotation, and
distinct locations on or near the keyboard that expands the input interaction space around the laptop.
		</p>
                <!-- <img class="figure img-fluid mx-auto d-block" src="http://via.placeholder.com/500x200.png"> -->
                <img class="figure col-xl-5 col-lg-5 col-md-5 col-sm-8 col-xs-12 img-fluid mx-auto d-block" src="img/Figure2.png">
               <p>
		This gives a design space of 36 postures that can be fully defined by variations along four parameters:
		</p>
                <ol>
                    <li>Hand (dominant, non-dominant)</li>
                    <li>Form (open, closed)</li>
                    <li>Orientation (0&#176;, 90&#176;, 180&#176;) </li>
                    <li>Surface (on, beside, below)</li>			
                </ol>

                <p><b>Finally,</b> all postures are characterized with a slightly extended thumb to appear unique for recognition without a keypress.</p>

                <!-- !!! Github URL here if you want to share it! -->
                <!-- <small>Source code available on <a href="#">GitHub</a>.</small> -->
            </div>

            <div id="exp1" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>!!! Experiment section </h1>
                <p>!!! A quick summary of our experiment. Remember, random people might read this who may or may not understand what we've done!</p>
                <!-- <img class="figure col-xl-4 col-lg-5 col-md-6 col-sm-8 col-xs-12 img-fluid mx-auto d-block" src="http://via.placeholder.com/700x700.png"> -->
                <img class="figure col-xl-5 col-lg-5 col-md-5 col-sm-8 col-xs-12 img-fluid mx-auto d-block" src="img/Figure3.png">
                <p>!!! Figures are fun. Don't overwhelm people with text, this is mostly just a place to show off some figures.</p>
                <!-- <img class="figure col-xl-6 col-md-8 col-sm-8 col-xs-12 img-fluid mx-auto d-block" src="http://via.placeholder.com/500x200.png"> -->
                <img class="figure col-xl-6 col-lg-6 col-md-6 col-sm-8 col-xs-12 img-fluid mx-auto d-block" src="img/Figure4.png">
                <p>!!! Add really high-level summaries so the figures have some context. Use different Bootstrap classes so figures show up at different sizes. Adjust to taste.</p>
                <!-- <img class="figure col-lg-10 img-fluid mx-auto d-block" src="http://via.placeholder.com/500x200.png"> -->
                <img class="figure col-xs-12 img-fluid mx-auto d-block" src="img/Figure6.png">
                <img class="figure col-xs-12 img-fluid mx-auto d-block" src="img/Figure8.png">
                <img class="figure col-xl-6 col-lg-6 col-md-6 col-sm-8 col-xs-12 img-fluid mx-auto d-block" src="img/Figure9.png">

            </div>
            
            <div id="disc" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>What Can We Learn?</h1>
                <ol>
                    <li>
                        <b>!!! Bold claim: </b>Have a few extra insights here. 
                    </li>
                    <li>
                        <b>!!! Bold claim: </b> Have a section here that answers "okay, but why should I care?".
                    </li>
                    <li>
                        <b>!!! Bolding is fun:</b> Wow look, another one!
                    </li>
                </ol>
            </div>

            <div id="disc" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>Dataset</h1>
                <p>
                    Some descriptive stats about the dataset
                </p>
                <img class="figure col-xl-6 col-lg-6 col-md-6 col-sm-8 col-xs-12 img-fluid mx-auto d-block" src="img/Figure5.png">
                <br/>
	        <a href="https://www.kaggle.com/nalinc/typealike">Kaggle Dataset</a>
            </div>

            <div id="publication" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>Publication</h1>
                <!-- <p>!!! AUTHORS. !!! YEAR. <b>!!! YOUR TITLE HERE</b>. In proceedings of !!! CONFERENCE ETC. DOI: <a class="doi-url" href="http://google.ca">!!! DOI URL (change the href too!)</a></p> -->
                <p>Nalin Chhibber, Hemant Surale, Fabrice Matulic, Daniel Vogel. 2021. <b>Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction</b>. In proceedings of In PACM on Human Computer Interaction, Vol. 5, ISS.
                    <!-- <a class="doi-url" href="http://google.ca"></a></p> -->            
                <br>
                <h2>BibTeX</h2>
            	<pre>
	            	<code>@inproceedings{Chhibber2021,<br>   author = {Nalin Chhibber, Hemant Surale, Fabrice Matulic, Daniel Vogel},<br>   title = {Typealike: Near-Keyboard Hand Postures for Expanded Laptop Interaction},<br>   year = {2021},<br>   publisher = {Association for Computing Machinery},<br>   booktitle = {In proceedings of In PACM on Human Computer Interaction, Vol. 5, ISS},<br>   keywords = {interaction techniques, input re-mapping},<br>   location = {ŁÓDŹ, POLAND},<br>   series = {ISS '21}<br>}</code>
				</pre>
            </div>

            <div id="contact" class="col-md-10 offset-md-1 col-xs-12 offset-xs-0 content-section">
                <h1>Contact Us</h1>
                <p>Questions? Feel free to contact:</p>
                <div class="grid-container">
			    	
                    <div class="grid-profile">
                        <img class="pad-right headshot grid-content" src="img/nalin_chhibber.png">
                        <div class="grid-content">
                            <a href="https://nalinc.github.io">Nalin Chhibber</a>
                            <br> M.Math Computer Science
                            <br>University of Waterloo
                            <br>nalin.chhibber [at] uwaterloo.ca
                        </div>
                    </div>
                    
                    <div class="grid-profile">
                        <img class="pad-right headshot grid-content" src="img/hemant_surale.jpeg">
                        <div class="grid-content">
                            <a href="https://sites.google.com/view/hemantsurale/home">Hemant Surale</a>
                            <br> PhD Computer Science
                            <br>University of Waterloo
                            <br>hemant.surale [at] uwaterloo.ca
                        </div>
                    </div>
                    
                    <div class="grid-profile">
                        <img class="pad-right headshot grid-content" src="img/fabrice_matulic.png">
                        <div class="grid-content">
                            <a href="http://hci.uwaterloo.ca/~fdmmatul/">Fabrice Matulic</a>
                            <br> Senior Researcher
                            <br> Preferred Networks Inc.
                            <br>fmatulic [at] preferred.jp
                        </div>
                    </div>
                    
                    <div class="grid-profile">
                        <img class="pad-right headshot grid-content" src="img/daniel_vogel.jpeg">
                        <div class="grid-content">
                            <a href="https://www.nonsequitoria.com/">Daniel Vogel</a>
                            <br> Associate Professor
                            <br>University of Waterloo
                            <br>dvogel [at] uwaterloo.ca
                        </div>
                    </div>
                </div>
                <!-- <ul>
                    <li><span class="contact-author-name">Nalin Chhibber </span>Uninversity of Waterloo <br>nalin.chhibber@uwaterloo.ca</li>
                    <li><span class="contact-author-name">Hemant Surale </span>!!! AUTHOR DESCRIPTION <br>!!! AUTHOR EMAIL</li>
                    <li><span class="contact-author-name">Fabrice Matulic </span>!!! AUTHOR DESCRIPTION <br>!!! AUTHOR EMAIL</li>
                    <li><span class="contact-author-name">Daniel Vogel </span>!!! AUTHOR DESCRIPTION <br>!!! AUTHOR EMAIL</li>
                </ul> -->
            </div>
            <hr class="rule col-md-10 offset-md-1"col-xs-12 offset-xs-0 >
            <p class="copyright text-center">
               <!-- !!! AUTHOR NAMES HERE, !!! INSTITUTION NAMES HERE © !!! YEAR -->
               Nalin Chhibber, Hemant Surale, Fabrice Matulic, Daniel Vogel <br/> 
               University of Waterloo, Preferred Networks Inc. © 2021
               <br>
               <!-- Blog post template by <a href="http://johannwentzel.ca">Johann Wentzel</a>. -->
            </p>

        </div>
    </body>
</html>
